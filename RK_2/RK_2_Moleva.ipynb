{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ИУ5-61Б, Молева А.А."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 1. Классификация текстов на основе методов наивного Байеса.\n",
    "\n",
    "Необходимо решить задачу классификации текстов на основе любого выбранного Вами датасета (кроме примера, который рассматривался в лекции). Классификация может быть бинарной или многоклассовой. Целевой признак из выбранного Вами датасета может иметь любой физический смысл, примером является задача анализа тональности текста.\n",
    "\n",
    "Необходимо сформировать признаки на основе CountVectorizer или TfidfVectorizer.\n",
    "\n",
    "В качестве классификаторов необходимо использовать два классификатора, не относящихся к наивным Байесовским методам (например, LogisticRegression, LinearSVC), а также Multinomial Naive Bayes (MNB), Complement Naive Bayes (CNB), Bernoulli Naive Bayes.\n",
    "\n",
    "Для каждого метода необходимо оценить качество классификации с помощью хотя бы одной метрики качества классификации (например, Accuracy).\n",
    "\n",
    "Сделате выводы о том, какой классификатор осуществляет более качественную классификацию на Вашем наборе данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Value\n",
       "0                           Wow... Loved this place.      1\n",
       "1                                 Crust is not good.      0\n",
       "2          Not tasty and the texture was just nasty.      0\n",
       "3  Stopped by during the late May bank holiday of...      1\n",
       "4  The selection on the menu was great and so wer...      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"datasets/sentiment labelled sentences/yelp_labelled.txt\", \n",
    "                   delimiter='\\t', header=None, names=['Text', 'Value'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий словарь для обучения моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Wow... Loved this place.',\n",
       " 'Crust is not good.',\n",
       " 'Not tasty and the texture was just nasty.',\n",
       " 'Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.',\n",
       " 'The selection on the menu was great and so were the prices.',\n",
       " 'Now I am getting angry and I want my damn pho.',\n",
       " \"Honeslty it didn't taste THAT fresh.)\",\n",
       " 'The potatoes were like rubber and you could tell they had been made up ahead of time being kept under a warmer.',\n",
       " 'The fries were great too.',\n",
       " 'A great touch.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_list = data.Text.tolist()\n",
    "vocab_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x2035 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9782 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabVect = CountVectorizer()\n",
    "vocabVect.fit_transform(vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Количество признаков = 2035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2035"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabVect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusVocab = vocabVect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Признак и его индекс в словаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wow=2012\n",
      "loved=1046\n",
      "this=1798\n",
      "place=1330\n",
      "crust=427\n",
      "is=943\n",
      "not=1195\n",
      "good=764\n",
      "tasty=1761\n",
      "and=64\n"
     ]
    }
   ],
   "source": [
    "for i in list(corpusVocab)[:10]:\n",
    "    print('{}={}'.format(i, corpusVocab[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x2035 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9782 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = vocabVect.transform(vocab_list)\n",
    "test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1000 строк - 1000 предложений в документе\n",
    "### 2035 столбцов - 2035 уникальных значений в документе"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-граммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x16553 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27378 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncv = CountVectorizer(ngram_range=(1, 3))\n",
    "ngram_features = ncv.fit_transform(vocab_list)\n",
    "ngram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['about taste like',\n",
       " 'about the',\n",
       " 'about the place',\n",
       " 'about this',\n",
       " 'about this place',\n",
       " 'about two',\n",
       " 'about two bites',\n",
       " 'about was',\n",
       " 'about was their',\n",
       " 'about working',\n",
       " 'about working eating',\n",
       " 'above',\n",
       " 'above and',\n",
       " 'above and beyond',\n",
       " 'above average',\n",
       " 'above average or',\n",
       " 'absolute',\n",
       " 'absolute must',\n",
       " 'absolute must visit',\n",
       " 'absolutely']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ncv.get_feature_names()[100:120]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Векторизация TfidVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1000x16553 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 27378 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfv = TfidfVectorizer(ngram_range=(1,3))\n",
    "tfidf_ngram_features = tfidfv.fit_transform(vocab_list)\n",
    "tfidf_ngram_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_ngram_features.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.3110249863005478,\n",
       " 0.407238517312785,\n",
       " 0.407238517312785,\n",
       " 0.1842360034601564,\n",
       " 0.16951209244619436,\n",
       " 0.20421138601952366,\n",
       " 0.36811828714125194,\n",
       " 0.407238517312785,\n",
       " 0.407238517312785]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Непустые значения нулевой строки\n",
    "[i for i in tfidf_ngram_features.todense()[0].getA1() if i>0][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Решение задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VectorizeAndClassify(vectorizers_list, classifiers_list):\n",
    "    for v in vectorizers_list:\n",
    "        for c in classifiers_list:\n",
    "            pipeline1 = Pipeline([(\"vectorizer\", v), (\"classifier\", c)])\n",
    "            score = cross_val_score(pipeline1, data['Text'], data['Value'], scoring='accuracy', cv=3).mean()\n",
    "            print('Векторизация - {}'.format(v))\n",
    "            print('Модель для классификации - {}'.format(c))\n",
    "            print('Accuracy = {}'.format(score))\n",
    "            print('===========================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, NuSVC, LinearSVC, OneClassSVM, SVR, NuSVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '10': 1, '100': 2, '11': 3, '12': 4,\n",
      "                            '15': 5, '17': 6, '1979': 7, '20': 8, '2007': 9,\n",
      "                            '23': 10, '30': 11, '30s': 12, '35': 13, '40': 14,\n",
      "                            '40min': 15, '45': 16, '4ths': 17, '5lb': 18,\n",
      "                            '70': 19, '85': 20, '90': 21, '99': 22, 'about': 23,\n",
      "                            'above': 24, 'absolute': 25, 'absolutely': 26,\n",
      "                            'absolutley': 27, 'accident': 28,\n",
      "                            'accommodations': 29, ...})\n",
      "Модель для классификации - LogisticRegression(C=3.0)\n",
      "Accuracy = 0.7770045494596394\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '10': 1, '100': 2, '11': 3, '12': 4,\n",
      "                            '15': 5, '17': 6, '1979': 7, '20': 8, '2007': 9,\n",
      "                            '23': 10, '30': 11, '30s': 12, '35': 13, '40': 14,\n",
      "                            '40min': 15, '45': 16, '4ths': 17, '5lb': 18,\n",
      "                            '70': 19, '85': 20, '90': 21, '99': 22, 'about': 23,\n",
      "                            'above': 24, 'absolute': 25, 'absolutely': 26,\n",
      "                            'absolutley': 27, 'accident': 28,\n",
      "                            'accommodations': 29, ...})\n",
      "Модель для классификации - LinearSVC()\n",
      "Accuracy = 0.7749965534396672\n",
      "===========================\n",
      "Векторизация - CountVectorizer(vocabulary={'00': 0, '10': 1, '100': 2, '11': 3, '12': 4,\n",
      "                            '15': 5, '17': 6, '1979': 7, '20': 8, '2007': 9,\n",
      "                            '23': 10, '30': 11, '30s': 12, '35': 13, '40': 14,\n",
      "                            '40min': 15, '45': 16, '4ths': 17, '5lb': 18,\n",
      "                            '70': 19, '85': 20, '90': 21, '99': 22, 'about': 23,\n",
      "                            'above': 24, 'absolute': 25, 'absolutely': 26,\n",
      "                            'absolutley': 27, 'accident': 28,\n",
      "                            'accommodations': 29, ...})\n",
      "Модель для классификации - KNeighborsClassifier()\n",
      "Accuracy = 0.6339962717208226\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '10': 1, '100': 2, '11': 3, '12': 4,\n",
      "                            '15': 5, '17': 6, '1979': 7, '20': 8, '2007': 9,\n",
      "                            '23': 10, '30': 11, '30s': 12, '35': 13, '40': 14,\n",
      "                            '40min': 15, '45': 16, '4ths': 17, '5lb': 18,\n",
      "                            '70': 19, '85': 20, '90': 21, '99': 22, 'about': 23,\n",
      "                            'above': 24, 'absolute': 25, 'absolutely': 26,\n",
      "                            'absolutley': 27, 'accident': 28,\n",
      "                            'accommodations': 29, ...})\n",
      "Модель для классификации - LogisticRegression(C=3.0)\n",
      "Accuracy = 0.7909975844107581\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '10': 1, '100': 2, '11': 3, '12': 4,\n",
      "                            '15': 5, '17': 6, '1979': 7, '20': 8, '2007': 9,\n",
      "                            '23': 10, '30': 11, '30s': 12, '35': 13, '40': 14,\n",
      "                            '40min': 15, '45': 16, '4ths': 17, '5lb': 18,\n",
      "                            '70': 19, '85': 20, '90': 21, '99': 22, 'about': 23,\n",
      "                            'above': 24, 'absolute': 25, 'absolutely': 26,\n",
      "                            'absolutley': 27, 'accident': 28,\n",
      "                            'accommodations': 29, ...})\n",
      "Модель для классификации - LinearSVC()\n",
      "Accuracy = 0.7910065754377132\n",
      "===========================\n",
      "Векторизация - TfidfVectorizer(vocabulary={'00': 0, '10': 1, '100': 2, '11': 3, '12': 4,\n",
      "                            '15': 5, '17': 6, '1979': 7, '20': 8, '2007': 9,\n",
      "                            '23': 10, '30': 11, '30s': 12, '35': 13, '40': 14,\n",
      "                            '40min': 15, '45': 16, '4ths': 17, '5lb': 18,\n",
      "                            '70': 19, '85': 20, '90': 21, '99': 22, 'about': 23,\n",
      "                            'above': 24, 'absolute': 25, 'absolutely': 26,\n",
      "                            'absolutley': 27, 'accident': 28,\n",
      "                            'accommodations': 29, ...})\n",
      "Модель для классификации - KNeighborsClassifier()\n",
      "Accuracy = 0.7529655403906901\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "vectorizers_list = [CountVectorizer(vocabulary = corpusVocab), TfidfVectorizer(vocabulary = corpusVocab)]\n",
    "classifiers_list = [LogisticRegression(C=3.0), LinearSVC(), KNeighborsClassifier()]\n",
    "VectorizeAndClassify(vectorizers_list, classifiers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['Text'], data['Value'], test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "\n",
    "def accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray) -> Dict[int, float]:\n",
    "    \"\"\"\n",
    "    Вычисление метрики accuracy для каждого класса\n",
    "    y_true - истинные значения классов\n",
    "    y_pred - предсказанные значения классов\n",
    "    Возвращает словарь: ключ - метка класса, \n",
    "    значение - Accuracy для данного класса\n",
    "    \"\"\"\n",
    "    # Для удобства фильтрации сформируем Pandas DataFrame \n",
    "    d = {'t': y_true, 'p': y_pred}\n",
    "    df = pd.DataFrame(data=d)\n",
    "    # Метки классов\n",
    "    classes = np.unique(y_true)\n",
    "    # Результирующий словарь\n",
    "    res = dict()\n",
    "    # Перебор меток классов\n",
    "    for c in classes:\n",
    "        # отфильтруем данные, которые соответствуют \n",
    "        # текущей метке класса в истинных значениях\n",
    "        temp_data_flt = df[df['t']==c]\n",
    "        # расчет accuracy для заданной метки класса\n",
    "        temp_acc = accuracy_score(\n",
    "            temp_data_flt['t'].values, \n",
    "            temp_data_flt['p'].values)\n",
    "        # сохранение результата в словарь\n",
    "        res[c] = temp_acc\n",
    "    return res\n",
    "\n",
    "def print_accuracy_score_for_classes(\n",
    "    y_true: np.ndarray, \n",
    "    y_pred: np.ndarray):\n",
    "    \"\"\"\n",
    "    Вывод метрики accuracy для каждого класса\n",
    "    \"\"\"\n",
    "    accs = accuracy_score_for_classes(y_true, y_pred)\n",
    "    if len(accs)>0:\n",
    "        print('Метка \\t Accuracy')\n",
    "    for i in accs:\n",
    "        print('{} \\t {}'.format(i, accs[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(v, c):\n",
    "    model = Pipeline(\n",
    "        [(\"vectorizer\", v), \n",
    "         (\"classifier\", c)])\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print_accuracy_score_for_classes(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метка \t Accuracy\n",
      "0 \t 0.80078125\n",
      "1 \t 0.8114754098360656\n",
      "============================\n",
      "Метка \t Accuracy\n",
      "0 \t 0.77734375\n",
      "1 \t 0.8401639344262295\n",
      "============================\n",
      "Метка \t Accuracy\n",
      "0 \t 0.49609375\n",
      "1 \t 0.8278688524590164\n",
      "============================\n",
      "Метка \t Accuracy\n",
      "0 \t 0.76171875\n",
      "1 \t 0.8401639344262295\n",
      "============================\n",
      "Метка \t Accuracy\n",
      "0 \t 0.48828125\n",
      "1 \t 0.8319672131147541\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "types = [[TfidfVectorizer(), LogisticRegression(C=5.0)], \n",
    "        [TfidfVectorizer(ngram_range=(1,3)), LogisticRegression(C=5.0)],\n",
    "        [TfidfVectorizer(ngram_range=(2,3)), LogisticRegression(C=5.0)],\n",
    "        [TfidfVectorizer(ngram_range=(1,4)), LogisticRegression(C=5.0)],\n",
    "        [TfidfVectorizer(ngram_range=(2,4)), LogisticRegression(C=5.0)]]\n",
    "for type_ in types:\n",
    "    sentiment(*type_)\n",
    "    print(\"============================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
